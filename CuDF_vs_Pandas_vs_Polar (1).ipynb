{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking Pandas, CUDF, and Polars\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Choosing the right tools for data manipulation in you day 2 day task as a Quant can significantly impact your workflow's efficiency. In this project, we compare three popular libraries: **Pandas**, **CUDF**, and **Polars**. We'll focus on common operations like `groupby` and `map` using a large dataset to see which library performs best.\n",
        "\n",
        "## Installation Steps\n",
        "\n",
        "### Check GPU Availability\n",
        "\n",
        "First, make sure you have a GPU available in your Colab environment. Run this command:\n",
        "\n",
        "```python\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "xrd4glT6MHy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8du5jeDhD1BQ",
        "outputId": "a9828bb5-90b5-4802-ded2-85196c0290c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 19 04:23:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0              29W /  70W |   1665MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install RAPIDS in Google Colab or Notebook\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "\n",
        "\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n"
      ],
      "metadata": {
        "id": "SId0lUoAMLgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import cudf\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "\n",
        "# Create a large DataFrame with 10 million rows and 20 columns\n",
        "data_size = 10**7\n",
        "num_columns = 20\n",
        "data = np.random.rand(data_size, num_columns)\n",
        "columns = [f'col{i}' for i in range(num_columns)]\n",
        "\n",
        "# Create Pandas DataFrame\n",
        "pdf = pd.DataFrame(data, columns=columns)\n",
        "pdf['group'] = np.random.randint(0, 100, size=data_size)  # Add a column for groupby\n",
        "\n",
        "# Convert to CUDF DataFrame\n",
        "gdf = cudf.DataFrame.from_pandas(pdf)\n",
        "\n",
        "# Create Polars DataFrame\n",
        "pl_df = pl.DataFrame(data, schema=columns)\n",
        "pl_df = pl_df.with_columns([\n",
        "    pl.Series('group', np.random.randint(0, 100, size=data_size))\n",
        "])\n",
        "\n",
        "# Define functions for various operations\n",
        "\n",
        "def pandas_groupby(df):\n",
        "    return df.groupby('group').sum()\n",
        "\n",
        "def cudf_groupby(df):\n",
        "    return df.groupby('group').sum()\n",
        "\n",
        "def polars_groupby(df):\n",
        "    return df.groupby('group').agg(pl.all().sum())\n",
        "\n",
        "def pandas_map(df):\n",
        "    return df['col0'].map(lambda x: x * 2)\n",
        "\n",
        "def cudf_map(df):\n",
        "    return df['col0'].apply(lambda x: x * 2)\n",
        "\n",
        "def polars_map(df):\n",
        "    return df.with_columns((pl.col('col0') * 2).alias('mapped_col0'))\n",
        "\n",
        "# Benchmark Groupby\n",
        "\n",
        "# Measure time for Pandas groupby\n",
        "start_time = time.time()\n",
        "pandas_groupby(pdf)\n",
        "pandas_groupby_time = time.time() - start_time\n",
        "\n",
        "# Measure time for CUDF groupby\n",
        "start_time = time.time()\n",
        "cudf_groupby(gdf)\n",
        "cudf_groupby_time = time.time() - start_time\n",
        "\n",
        "# Measure time for Polars groupby\n",
        "start_time = time.time()\n",
        "polars_groupby(pl_df)\n",
        "polars_groupby_time = time.time() - start_time\n",
        "\n",
        "print(f\"Pandas groupby time: {pandas_groupby_time} seconds\")\n",
        "print(f\"CUDF groupby time: {cudf_groupby_time} seconds\")\n",
        "print(f\"Polars groupby time: {polars_groupby_time} seconds\")\n",
        "\n",
        "# Benchmark Map\n",
        "\n",
        "# Measure time for Pandas map\n",
        "start_time = time.time()\n",
        "pandas_map(pdf)\n",
        "pandas_map_time = time.time() - start_time\n",
        "\n",
        "# Measure time for CUDF map\n",
        "start_time = time.time()\n",
        "cudf_map(gdf)\n",
        "cudf_map_time = time.time() - start_time\n",
        "\n",
        "# Measure time for Polars map\n",
        "start_time = time.time()\n",
        "polars_map(pl_df)\n",
        "polars_map_time = time.time() - start_time\n",
        "\n",
        "print(f\"Pandas map time: {pandas_map_time} seconds\")\n",
        "print(f\"CUDF map time: {cudf_map_time} seconds\")\n",
        "print(f\"Polars map time: {polars_map_time} seconds\")\n",
        "\n",
        "# Repeat the measurements for more accurate results\n",
        "\n",
        "# Measure time for Pandas groupby (repeated)\n",
        "pandas_groupby_times = []\n",
        "for _ in range(5):\n",
        "    start_time = time.time()\n",
        "    pandas_groupby(pdf)\n",
        "    pandas_groupby_times.append(time.time() - start_time)\n",
        "\n",
        "# Measure time for CUDF groupby (repeated)\n",
        "cudf_groupby_times = []\n",
        "for _ in range(5):\n",
        "    start_time = time.time()\n",
        "    cudf_groupby(gdf)\n",
        "    cudf_groupby_times.append(time.time() - start_time)\n",
        "\n",
        "# Measure time for Polars groupby (repeated)\n",
        "polars_groupby_times = []\n",
        "for _ in range(5):\n",
        "    start_time = time.time()\n",
        "    polars_groupby(pl_df)\n",
        "    polars_groupby_times.append(time.time() - start_time)\n",
        "\n",
        "print(f\"Average Pandas groupby time: {np.mean(pandas_groupby_times)} seconds\")\n",
        "print(f\"Average CUDF groupby time: {np.mean(cudf_groupby_times)} seconds\")\n",
        "print(f\"Average Polars groupby time: {np.mean(polars_groupby_times)} seconds\")\n",
        "\n",
        "# Measure time for Pandas map (repeated)\n",
        "pandas_map_times = []\n",
        "for _ in range(5):\n",
        "    start_time = time.time()\n",
        "    pandas_map(pdf)\n",
        "    pandas_map_times.append(time.time() - start_time)\n",
        "\n",
        "# Measure time for CUDF map (repeated)\n",
        "cudf_map_times = []\n",
        "for _ in range(5):\n",
        "    start_time = time.time()\n",
        "    cudf_map(gdf)\n",
        "    cudf_map_times.append(time.time() - start_time)\n",
        "\n",
        "# Measure time for Polars map (repeated)\n",
        "polars_map_times = []\n",
        "for _ in range(5):\n",
        "    start_time = time.time()\n",
        "    polars_map(pl_df)\n",
        "    polars_map_times.append(time.time() - start_time)\n",
        "\n",
        "print(f\"Average Pandas map time: {np.mean(pandas_map_times)} seconds\")\n",
        "print(f\"Average CUDF map time: {np.mean(cudf_map_times)} seconds\")\n",
        "print(f\"Average Polars map time: {np.mean(polars_map_times)} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mWY-bJlqEQZ-",
        "outputId": "0ad024f6-2e7c-423f-a0fd-b60bc554618c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-094b7c92918b>:35: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
            "  return df.groupby('group').agg(pl.all().sum())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas groupby time: 0.5358314514160156 seconds\n",
            "CUDF groupby time: 0.07317042350769043 seconds\n",
            "Polars groupby time: 0.7813115119934082 seconds\n",
            "Pandas map time: 2.6636924743652344 seconds\n",
            "CUDF map time: 0.7424323558807373 seconds\n",
            "Polars map time: 0.05660867691040039 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-094b7c92918b>:35: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
            "  return df.groupby('group').agg(pl.all().sum())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Pandas groupby time: 0.5473709583282471 seconds\n",
            "Average CUDF groupby time: 0.06942968368530274 seconds\n",
            "Average Polars groupby time: 1.1076735019683839 seconds\n",
            "Average Pandas map time: 2.900290775299072 seconds\n",
            "Average CUDF map time: 0.005760478973388672 seconds\n",
            "Average Polars map time: 0.050056076049804686 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Benchmarking Results\n",
        "\n",
        "| Operation | Pandas Time (s) | CUDF Time (s) | Polars Time (s) |\n",
        "|-----------|------------------|---------------|-----------------|\n",
        "| Groupby   | 0.5474           | 0.0694        | 1.1077          |\n",
        "| Map       | 2.9003           | 0.0058        | 0.0501          |\n",
        "\n",
        "\n",
        "## Observations\n",
        "\n",
        "### CUDF: The Power of GPU Acceleration\n",
        "CUDF demonstrated remarkable performance, particularly in the `map` operation, where it completed the task in just 0.006 seconds on average. This highlights the significant advantage of GPU acceleration for large-scale data operations. For `groupby`, CUDF also outperformed the others, showcasing its efficiency in parallel processing.\n",
        "\n",
        "### Polars: Efficient and Versatile\n",
        "Polars showed impressive results, especially in the `map` operation, completing it in 0.05 seconds on average. Although it was slower than CUDF in the `groupby` operation, Polars still outperformed Pandas, making it a strong contender for high-performance data manipulation tasks.\n",
        "\n",
        "### Pandas: Reliable but Slower\n",
        "Pandas, while being the most familiar and widely used library, was the slowest in both operations. This is expected given that Pandas operates on CPU and is not optimized for parallel processing. However, its ease of use and extensive ecosystem make it a go-to choice for many data scientists.\n",
        "\n",
        "## Conclusion\n",
        "The benchmark highlights that for large datasets and performance-critical applications, leveraging GPU-accelerated libraries like CUDF can offer substantial benefits. Polars also provides an excellent balance between performance and ease of use, making it a valuable tool for data manipulation tasks.\n"
      ],
      "metadata": {
        "id": "xtOPng97MzKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect with Me on LinkedIn\n",
        "\n",
        "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/in/akjha002/)\n",
        "\n",
        "I invite you to connect with me on LinkedIn. Follow my profile for insights, updates, and professional networking opportunities in , financial mathematics, and quantitative analysis. Click the badge above or follow this link: [Amit](https://www.linkedin.com/in/akjha002/).\n",
        "\n",
        "Let's connect and grow together in the world of Quant!\n"
      ],
      "metadata": {
        "id": "-VcBXAwIOZNh"
      }
    }
  ]
}